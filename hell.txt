SPARK:
sudo apt update
sudo apt install default-jdk
sudo apt install scala
sudo su
mkdir /opt/spark
cd /opt/spark
wget https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz
tar xvf spark-3.5.3-bin-hadoop3.tgz
cd
ll
nano .bashrc
SPARK_HOME=/opt/spark/spark-3.5.3-bin-hadoop3
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/bin
source .bashrc
spark-shell
CODE:
import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder.appName("Ordered Word List").getOrCreate()


val rdd = spark.sparkContext.textFile("/home/osboxes/sample.txt")


val indexedWords = rdd.flatMap(line => line.split("\\W+")).zipWithIndex()

val orderedUniqueWords = indexedWords.distinct()
  .sortBy { case (_, index) => index }
  .map { case (word, _) => word }

orderedUniqueWords.collect().foreach(println)

spark.stop()

DOCKER:
sudo usermod -aG docker $USER
sudo systemctl start docker
sudo systemctl status docker
mkdir test
cd test
touch readme.txt
touch DockerFile
ls
gedit DockerFile
FROM ubuntu
CMD ["echo","hello i am docker"]S
sudo docker build -t mydocker .
sudo docker images
sudo docker run mydocker
sudo chown -R $(whoami) ~/.docker
docker login
docker images
docker ps
docker ps -a
docker pull ubuntu
docker run ubuntu
docker run -d ubuntu
docker run -it ubuntu /bin/bash
